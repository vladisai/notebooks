{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from math import sqrt\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class RBM(nn.Module):\n",
    "    DREAM_ITERATIONS = 1\n",
    "    \n",
    "    def __init__(self, visible, hidden):  \n",
    "        super(RBM, self).__init__()\n",
    "        self.visible_bias = nn.Parameter(torch.empty((visible)).uniform_(-2/visible, 2/visible)) # visible bias\n",
    "        self.hidden_bias = nn.Parameter(torch.empty((hidden)).uniform_(-2/hidden, 2/hidden))\n",
    "        self.visible_size = visible\n",
    "        self.hidden_size = hidden\n",
    "        r = min(1/visible, 1/hidden)\n",
    "        self.W = nn.Parameter(torch.empty((hidden, visible)).uniform_(-r, r))\n",
    "        \n",
    "    @staticmethod\n",
    "    def to_binary_sample(v):\n",
    "        v = torch.sigmoid(v) # torch.sigmiod\n",
    "        try:\n",
    "            result = torch.bernoulli(v)\n",
    "        except:\n",
    "            print(v) \n",
    "            exit(0)\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_binary_optimal(v):\n",
    "        return (v > 0).float()\n",
    "    \n",
    "    @staticmethod\n",
    "    def linear(W, bias, x):\n",
    "        result = torch.t(W @ x) + bias\n",
    "        result = torch.t(result)\n",
    "        return result\n",
    "    \n",
    "    def visible_to_hidden_sample(self, visible):\n",
    "        result = RBM.linear(self.W, self.hidden_bias, visible)\n",
    "        return RBM.to_binary_sample(result)\n",
    "    \n",
    "    def visible_to_hidden_optimal(self, visible):\n",
    "        result = RBM.linear(self.W, self.hidden_bias, visible)\n",
    "        return RBM.to_binary_optimal(result)\n",
    "    \n",
    "    def hidden_to_visible_sample(self, hidden):\n",
    "        result = RBM.linear(torch.t(self.W), self.visible_bias, hidden)\n",
    "        return RBM.to_binary_sample(result)\n",
    "    \n",
    "    def hidden_to_visible_optimal(self, hidden):\n",
    "        result = RBM.linear(torch.t(self.W), self.visible_bias, hidden)\n",
    "        return RBM.to_binary_optimal(result)\n",
    "    \n",
    "    def dream(self, start, iterations=2):\n",
    "        v = start\n",
    "        h = None\n",
    "        iterations = random.randint(1, iterations)\n",
    "        for i in range(iterations):\n",
    "            h = self.visible_to_hidden_sample(v)\n",
    "            v = self.hidden_to_visible_sample(h)\n",
    "        return (v, h)    \n",
    "    \n",
    "    def forward(self, v, h):\n",
    "        proposed_h = self.W @ v\n",
    "        energy = torch.trace(-1 * torch.t(h) @ self.W @ v)\n",
    "        energy += torch.sum(-torch.t(self.visible_bias) @ v)\n",
    "        energy += torch.sum(-torch.t(self.hidden_bias) @ h)\n",
    "        energy /= v.shape[0]\n",
    "        return energy\n",
    "    \n",
    "    def get_likelihood(self, v):\n",
    "        h_opt = self.visible_to_hidden_optimal(v)\n",
    "        return self.forward(v, h_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RBM(4, 3)\n",
    "x = torch.empty(4, 2).random_(0, 2)\n",
    "h = torch.empty(3, 2).random_(0, 2)\n",
    "print(m(x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "IMAGE_SIZE = (28, 28)\n",
    "VISIBLE_SIZE = IMAGE_SIZE[0] * IMAGE_SIZE[1]\n",
    "HIDDEN_SIZE = 20\n",
    "\n",
    "def transform(x):\n",
    "    x = x.view(VISIBLE_SIZE)\n",
    "    x[x > 0.5] = 1\n",
    "    x[x <= 0.5] = 0\n",
    "    return x\n",
    "\n",
    "ds_train = torchvision.datasets.MNIST('./files/', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transform\n",
    "                       ]))\n",
    "ds_test = torchvision.datasets.MNIST('./files/', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transform\n",
    "                       ]))\n",
    "# can use transform here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 128\n",
    "batch_size_test = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "model = RBM(VISIBLE_SIZE, HIDDEN_SIZE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "def test_loss():\n",
    "    for z, _ in test_loader:\n",
    "        z.t_()\n",
    "        print(model.get_likelihood(z))\n",
    "        break\n",
    "        \n",
    "def loss(positive_phase, negative_phase):\n",
    "    return positive_phase - negative_phase\n",
    "        \n",
    "test_loss()\n",
    "train_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "for i in tqdm(range(EPOCHS)):\n",
    "    for x, y in tqdm(train_loader, leave=None):\n",
    "        x.t_()\n",
    "        \n",
    "        h_opt = model.visible_to_hidden_sample(x)\n",
    "        (x_bad, h_bad) = model.dream(x)\n",
    "        \n",
    "        positive_phase = model(x, h_opt)\n",
    "        negative_phase = model(x, h_bad)\n",
    "        \n",
    "        l = loss(positive_phase, negative_phase)\n",
    "        train_loss.append(l.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_tensor = torch.tensor(train_loss).view(1, 1, -1)\n",
    "print(train_loss_tensor.shape)\n",
    "KERNEL_SIZE = 20\n",
    "conv_loss = torch.nn.functional.conv1d(train_loss_tensor, torch.ones(1, 1, KERNEL_SIZE) / KERNEL_SIZE)\n",
    "conv_loss.squeeze_()\n",
    "plt.plot(conv_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow((model.visible_bias).view(*IMAGE_SIZE).detach().numpy())\n",
    "\n",
    "f, axarr = plt.subplots(4,5, figsize=(10, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(5):\n",
    "        axarr[i, j].imshow((model.W[i * 5 + j]).view(*IMAGE_SIZE).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader))\n",
    "x.t_()\n",
    "print(x.shape)\n",
    "h = model.visible_to_hidden_optimal(x)\n",
    "v = model.hidden_to_visible_optimal(h)\n",
    "print(v.shape)\n",
    "\n",
    "f, axarr = plt.subplots(2,5, figsize=(10, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    ind = random.randint(0, v.shape[1] - 1)\n",
    "    axarr[0, i].imshow(x[:, ind].view(28, 28))\n",
    "    axarr[1, i].imshow(v[:, ind].detach().view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
